==================================================================
✝ SERAPHIM vLLM Deployment Job - SLURM PREP ✝
Job Start Time: Sat May 10 09:46:19 AM UTC 2025
Job ID: 461 running on Node: ki-g0002.rz.fh-ingolstadt.de (Short: ki-g0002)
Slurm Output File (template based on %j): /home/aimotion_api/SERAPHIM/scripts/vllm_service_%j.out
Slurm Error File (template based on %j): /home/aimotion_api/SERAPHIM/scripts/vllm_service_%j.err
Model: EleutherAI/gpt-j-6b
Conda Env: seraphim_vllm_env
==================================================================
Sourcing Conda from /home/aimotion_api/anaconda3/etc/profile.d/conda.sh
Activating Conda Environment: seraphim_vllm_env
Conda environment 'seraphim_vllm_env' activated. Path: /home/aimotion_api/anaconda3/envs/seraphim_vllm_env
HF_TOKEN not provided.

Starting vLLM API Server in background...
Command: vllm serve EleutherAI/gpt-j-6b     --host 0.0.0.0     --port 8000     --trust-remote-code     --max-model-len 16384
vLLM service log will be: /home/aimotion_api/SERAPHIM/scripts/vllm_logs/vllm_service_.log
vLLM Service potentially started with PID: 736800. Waiting briefly for initialization...
ERROR: vLLM process 736800 does not seem to be running. Check /home/aimotion_api/SERAPHIM/scripts/vllm_logs/vllm_service_.log for errors.

==================================================================
✝ SERAPHIM vLLM Deployment Job - SERVICE STATUS ✝
Job ID: 461 on Node: ki-g0002.rz.fh-ingolstadt.de (Short: ki-g0002)
Model: EleutherAI/gpt-j-6b
Configured Service Port: 8000
vLLM Service Log File: /home/aimotion_api/SERAPHIM/scripts/vllm_logs/vllm_service_.log
---
The vLLM service is running in the background (PID: 736800).
To find the API endpoint:
  1. Check the vLLM log: cat /home/aimotion_api/SERAPHIM/scripts/vllm_logs/vllm_service_.log
  2. Look for lines like 'Uvicorn running on http://<ip_address>:8000'
  3. The API will be accessible on the node ki-g0002 at that address.
     Typically: http://ki-g0002:8000
     OpenAI API Docs (Swagger UI): http://ki-g0002:8000/docs
==================================================================
Slurm script finished its main tasks. The vLLM service (PID: 736800) should continue in the background.
